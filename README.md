## Common-Crawl
### Objective
This repository is to retrieve text data of web pages from Common Crawl.
### Procedures 
1. Predefine:
- Define the number of index  
Currently available index collections are listed: [CommonCrawl_Index Collections](http://index.commoncrawl.org/). It will be upodated periodically.
- Define targeting domains
2. Settle down Python environment
- [Python environment](https://github.com/lli130/Tensor-Flow)
- [git clone crawl functions](https://github.com/lli130/Common-Crawl/tree/cdx-index-client)
3. Fetch URL from specific domains  
[Fetch URL][https://github.com/lli130/Common-Crawl/blob/master/url_fetch.py]
4. Process URL to get WET text data of web pages
[Process URL][]

